{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as tt\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train']\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'D:/CSE project/ASL_Dataset2'\n",
    "\n",
    "print(os.listdir(data_dir))\n",
    "classes = os.listdir(data_dir + \"/train/train/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = tt.Compose(\n",
    "    [\n",
    "        #tt.RandomRotation(degrees=15),\n",
    "        tt.Resize((64,64)), #was 32\n",
    "        tt.Grayscale(num_output_channels=1),\n",
    "        tt.ToTensor(),\n",
    "        tt.Normalize([0.5], [0.5])\n",
    "    ]\n",
    ")\n",
    "dataset = ImageFolder(data_dir+\"/train/train\", transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '3', '4', '5', '7', '8', '9', 'A', 'B', 'Baby', 'Brother', 'C', 'D', 'Dont_like', 'E', 'F', 'Friend', 'G', 'H', 'Help', 'House', 'I', 'J', 'K', 'L', 'Like', 'Love', 'M', 'Make', 'More', 'N', 'Name', 'No', 'O_OR_0', 'P', 'Pay', 'Play', 'Q', 'R', 'S', 'Stop', 'T', 'U', 'V_OR_2', 'W_OR_6', 'With', 'X', 'Y', 'Yes', 'Z', 'nothing']\n"
     ]
    }
   ],
   "source": [
    "print(dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203000\n"
     ]
    }
   ],
   "source": [
    "random_seed = 42\n",
    "torch.manual_seed(random_seed);\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162400 40600\n"
     ]
    }
   ],
   "source": [
    "val_size = 40600\n",
    "train_size = len(dataset) - val_size\n",
    "\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print(len(train_ds), len(val_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_example(img, label):\n",
    "    print('Label: ', dataset.classes[label], \"(\"+str(label)+\")\")\n",
    "    plt.imshow((img.permute(1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  1 (0)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_example(*dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    # Pick GPU if available, else CPU \n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    # Move tensor(s) to chosen device \n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    # Wrap a dataloader to move data to a device \n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "     #   Yield a batch of data after moving it to device\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "     #   Number of batches\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size= 256\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_dl = DataLoader(val_ds, batch_size*2, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "\n",
    "def show_batch(dl):\n",
    "    for images, labels in dl:\n",
    "        fig, ax = plt.subplots(figsize=(16, 8))\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_batch(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "val_dl = DeviceDataLoader(val_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassificationBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASLModel(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "                                # input: 256 x 1 x 64 x 64   \n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),                                         \n",
    "            nn.MaxPool2d(2, 2), # output: 32 x 32 x 32 \n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 64 x 16 x 16\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),  # output: 128 x 16 x 16\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # output: 256 x 8 x 8\n",
    "            \n",
    "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # output: 384 x 4 x 4\n",
    "            \n",
    "            nn.Conv2d(384, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # output: 512 x 2 x 2\n",
    "            nn.Dropout(0.50),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512*2*2, 51)) \n",
    "            \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ASLModel(\n",
       "  (network): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "    (11): Dropout(p=0.25, inplace=False)\n",
       "    (12): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): ReLU()\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (16): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (18): ReLU()\n",
       "    (19): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (20): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (22): ReLU()\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Dropout(p=0.5, inplace=False)\n",
       "    (25): Flatten(start_dim=1, end_dim=-1)\n",
       "    (26): Linear(in_features=2048, out_features=51, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ASLModel()\n",
    "to_device(model, device);\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in tqdm(val_loader)]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        loop = tqdm(train_loader)\n",
    "        # Training Phase \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in loop:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = to_device(ASLModel(), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [03:09<00:00,  2.37s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 3.9320521354675293, 'val_acc': 0.018428761512041092}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = [evaluate(model, val_dl)]\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 15\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████████████████████████████████████████████████████▉                        | 444/635 [18:57<08:09,  2.56s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-5f6b37c59350>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-d799a4ec50c8>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(epochs, lr, model, train_loader, val_loader, opt_func)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mtrain_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m             \u001b[0mtrain_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-538442434839>\u001b[0m in \u001b[0;36mtraining_step\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m                  \u001b[1;31m# Generate predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Calculate loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-ce826081c971>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, xb)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    437\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 439\u001b[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    440\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracies(history):\n",
    "    accuracies = [x['val_acc'] for x in history]\n",
    "    plt.plot(accuracies, '-x')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('Accuracy vs. No. of epochs');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(history):\n",
    "    train_losses = [x.get('train_loss') for x in history]\n",
    "    val_losses = [x['val_loss'] for x in history]\n",
    "    plt.plot(train_losses, '-bx')\n",
    "    plt.plot(val_losses, '-rx')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.title('Loss vs. No. of epochs');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracies(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = [evaluate(model, val_dl)]\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'CNN0.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), 'CNN0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single(input, target, model):\n",
    "    predictions = model(input)\n",
    "    _, preds = torch.max(predictions, dim=1)\n",
    "    \n",
    "    print(\"Target:\", target)\n",
    "    print(\"Prediction:\", preds)\n",
    "    print(\"Predicted Label:\", dataset.classes[preds[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input, label in val_dl:\n",
    "    show_example(input[10].cpu(), label[10].cpu())\n",
    "    predict_single(input[10].view(1, 1, 64, 64), label[10], model) # Was predict_single(input[0].view(1, 3, 32, 32)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
